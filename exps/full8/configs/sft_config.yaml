# SFT 训练配置。路径等元信息使用占位符，与 verl 模板一致（full8 自动替换，其余需在实验目录中替换）。

# 按实验修改：base 模型路径（full8 = Thinking，与 verl7/verl8 同基座）
model: "/dfs/data/models/Qwen3-4B-Thinking-2507"
loss_scale: "default"
model_type: "qwen3"
template: "qwen3"
train_type: "full"

# 与 RL（verl7/verl8/verl9）同数据：train.parquet→train.jsonl、test.parquet→test.jsonl，分开指定。
# 由 parquet_to_openai_messages --output_dir data/hardgen_1k 生成，见 README。
dataset:
  - "/dfs/data/work/hardtry/data/hardgen_1k/train.jsonl"
val_dataset:
  - "/dfs/data/work/hardtry/data/hardgen_1k/test.jsonl"
max_length: 10240
split_dataset_ratio: 0

attn_impl: "flash_attention_2"
gradient_checkpointing: true
packing: true

torch_dtype: "bfloat16"
dataloader_num_workers: 8

num_train_epochs: 1
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
learning_rate: 1e-5
warmup_ratio: 0.05
lr_scheduler_type: "cosine"
gradient_accumulation_steps: 16
max_grad_norm: 1.0
weight_decay: 0.01

eval_steps: 10
save_steps: 10
save_total_limit: 2
logging_steps: 10
eval_strategy: "steps"
save_strategy: "steps"
eval_on_start: true
# 按实验修改：checkpoint 输出目录
output_dir: "/dfs/data/work/hardtry/checkpoints/full8"
seed: 42

report_to: "swanlab"
swanlab_project: "hardtry"
swanlab_exp_name: "full8"

fsdp: "fsdp2"
